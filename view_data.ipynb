{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# neural network packages\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# data processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "\n",
    "# to estimate the HAR model\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# own helping code for estimation, data processing etc.\n",
    "from utils.estimating import model_estimator, EarlyStopper, kfolds_fit_and_evaluate_model, single_fit_and_evaluate_model, fit_and_evaluateHAR\n",
    "from utils.preprocessing import PreProcessor, data_to_loaders\n",
    "from utils.functions import get_ticker_daily_close, print_nicely, reset_model_weights\n",
    "from utils.modelbuilder import ForwardNeuralNetwork\n",
    "\n",
    "# ignore annoying warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data to Features, Targets and Divide in Training/Validation Data\n",
    "- First the features are computed (previous daily/weekly/monthly volatility)\n",
    "- Then the data seperated into training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 9286\n",
      "shape har featurs: (9264, 4) of type <class 'numpy.ndarray'>\n",
      "shape nn features: (9264, 3) of type <class 'numpy.ndarray'>\n",
      "shape targets: (9264, 1) of type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "# file_name = \"msft_stock.csv\"\n",
    "# data = pd.read_csv(\"data/\" + file_name)\n",
    "# returns = data[\"price\"].apply(np.log).diff()\n",
    "\n",
    "# or through yahoo finance\n",
    "prices = get_ticker_daily_close(\"MSFT\")\n",
    "returns = prices.apply(np.log).diff()\n",
    "print(f\"Total observations: {len(returns)}\")\n",
    "\n",
    "################################################################\n",
    "# targets are just the squared returns\n",
    "targets = returns ** 2\n",
    "\n",
    "# features for HAR (realized daily/weekly/monthly volatility)\n",
    "features_har = np.zeros(shape=(len(targets), 3))\n",
    "features_har[:, 0] = targets.shift(1).values\n",
    "features_har[:, 1] = targets.rolling(5).apply(np.mean).shift(1).values\n",
    "features_har[:, 2] = targets.rolling(21).apply(np.mean).shift(1).values\n",
    "    \n",
    "# # features and targets to numpy array\n",
    "features_har = features_har\n",
    "features = features_har.copy() # or df.values # HAR and NN same input features\n",
    "targets = targets.values.reshape(-1,1)\n",
    "\n",
    "# add constant for har features and drop nan values\n",
    "features_har = sm.add_constant(features_har)\n",
    "\n",
    "# remove the first few observations due to no estimation for monthly volatility available\n",
    "start_index = 22\n",
    "features_har = features_har[start_index:]\n",
    "features = features[start_index:]\n",
    "targets = targets[start_index:]\n",
    "\n",
    "# final overview if features and targets\n",
    "print(f\"shape har featurs: {features_har.shape} of type {type(features_har)}\")\n",
    "print(f\"shape nn features: {features.shape} of type {type(features)}\")\n",
    "print(f\"shape targets: {targets.shape} of type {type(targets)}\")\n",
    "\n",
    "# split the data into the features set (used for cross validation and ultimately estimating the final model) and testing data\n",
    "train_size = .8 #.6\n",
    "features_har, features_har_validation, _placeholder, targets_validation = train_test_split(features_har, targets, shuffle=False, train_size = train_size)\n",
    "features, features_validation, targets, targets_validation = train_test_split(features, targets, shuffle=False, train_size = train_size)\n",
    "\n",
    "# # for model specification and final estimation\n",
    "# features, features_har, targets\n",
    "# # for model comparison\n",
    "# features_validation, features_har_validation, targets_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_vol_daily(ticker):\n",
    "    prices = get_ticker_daily_close(ticker)\n",
    "    returns = prices.apply(np.log).diff()\n",
    "    targets = returns ** 2\n",
    "    avg_targets = np.mean(targets)\n",
    "    return avg_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MU   : 0.1472258%\n",
      "GOLD : 0.0708661%\n",
      "MSFT : 0.0458784%\n",
      "KO   : 0.0213114%\n",
      "AAPL : 0.0824258%\n",
      "ASML : 0.0959555%\n"
     ]
    }
   ],
   "source": [
    "stocks = [\"MU\", \"GOLD\", \"MSFT\", \"KO\", \"AAPL\", \"ASML\"]\n",
    "for stock in stocks:\n",
    "    print(\"{:5}: {:1.7%}\".format(stock , get_avg_vol_daily(stock)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
