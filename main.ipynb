{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "from ml.models.simpleneuralnetwork import SimpleNeuralNetwork\n",
    "from ml.utils.preprocessing.preprocessor import PreProcessingData\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_daily_close(ticker = \"AAPL\"):\n",
    "    \"\"\" returns the daily close price for a maximum period for specified ticker \"\"\"\n",
    "    import yfinance\n",
    "    \n",
    "    tick = yfinance.Ticker(ticker)\n",
    "    return tick.history(period = \"max\", interval = \"1d\")[\"Close\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data to Features and Targets Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 9286\n",
      "shape features: (9259, 20) of type <class 'numpy.ndarray'>\n",
      "shape targets: (9259, 1) of type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# file_name = \"msft_stock.csv\"\n",
    "# data = pd.read_csv(\"data/\" + file_name)\n",
    "# returns = data[\"price\"].apply(np.log).diff()\n",
    "\n",
    "# or through yahoo finance\n",
    "prices = get_ticker_daily_close(\"MSFT\")\n",
    "returns = prices.apply(np.log).diff()\n",
    "print(f\"Total observations: {len(returns)}\")\n",
    "\n",
    "################################################################\n",
    "# targets are just the returns squared\n",
    "targets = returns ** 2\n",
    "\n",
    "# features are the targets with a certain lag\n",
    "df = pd.DataFrame({})\n",
    "lags = 20\n",
    "for i in range(1, lags+1):\n",
    "    df[f\"lag_{i}\"] = targets.shift(i)\n",
    "\n",
    "df_har = pd.DataFrame({})\n",
    "df_har[\"rv_d\"] = targets.shift(1)\n",
    "df_har[\"rv_w\"] = targets.rolling(5).apply(np.mean)\n",
    "df_har[\"rv_m\"] = targets.rolling(20).apply(np.mean)\n",
    "    \n",
    "# numpy array with features and targets\n",
    "features_har = df_har.values\n",
    "features = df.values\n",
    "targets = targets.values.reshape(-1,1)\n",
    "\n",
    "# drop nan values\n",
    "features = features[lags+1:-max(1, int(.3*lags))]\n",
    "targets = targets[lags+1:-max(1, int(.3*lags))]\n",
    "\n",
    "print(f\"shape features: {features.shape} of type {type(features)}\")\n",
    "print(f\"shape targets: {targets.shape} of type {type(targets)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Kfold Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: (1,)\n",
      "avg score: 0.0001800380678560032\n",
      "model: (1,)\n",
      "avg score: 1.067804701207753e-06\n"
     ]
    }
   ],
   "source": [
    "model_specifications = ((1,),)\n",
    "for model_specification in model_specifications:\n",
    "\n",
    "    score_nn = []\n",
    "    score_har = []\n",
    "    \n",
    "    kfold = TimeSeriesSplit(n_splits = 5, max_train_size = 8000, test_size = 500)\n",
    "    for train_index, test_index in kfold.split(features):\n",
    "        \n",
    "        # split data\n",
    "        features_train, features_test, targets_train, targets_test = \\\n",
    "            features[train_index], features[test_index], targets[train_index], targets[test_index]\n",
    "        features_train_har, features_test_har = features[train_index], features[test_index]\n",
    "\n",
    "        # fit normalizer on train features and normalize data\n",
    "        scaler = StandardScaler()\n",
    "        features_train = scaler.fit_transform(features_train)\n",
    "        features_test = scaler.transform(features_test)\n",
    "\n",
    "        #=========================================================================================\n",
    "        #===================================ESTIMATE HAR==========================================\n",
    "        #=========================================================================================\n",
    "        mod = OLS(targets_train, features_train_har, hasconst = True)\n",
    "        mod = mod.fit()\n",
    "        pred = mod.predict(features_test_har)\n",
    "        \n",
    "        # plt.plot(pred, label = \"pred\")\n",
    "        # plt.plot(targets_test, label = \"target\")\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        \n",
    "        loss = np.var(targets_test - pred)\n",
    "        score_har += [loss]\n",
    "\n",
    "        #=========================================================================================\n",
    "        #====================================ESTIMATE NN==========================================\n",
    "        #=========================================================================================\n",
    "        # all to tensor after transform\n",
    "        features_train_tensor = torch.tensor(features_train, dtype=torch.float32)\n",
    "        features_test_tensor = torch.tensor(features_test, dtype=torch.float32)\n",
    "        targets_train_tensor = torch.tensor(targets_train, dtype=torch.float32)\n",
    "        targets_test_tensor = torch.tensor(targets_test, dtype=torch.float32)\n",
    "\n",
    "        # to data loader so torch can handle the data efficiently\n",
    "        trainloader = torch.utils.data.DataLoader( [(feature, target) for feature, target in zip(features_train_tensor, targets_train_tensor)], batch_size = 20)\n",
    "        # testloader  = torch.utils.data.DataLoader( [(feature, target) for feature, target in zip(features_test, targets_test)], batch_size = 10)\n",
    "        \n",
    "        # estimate the model\n",
    "        model = SimpleNeuralNetwork(\n",
    "            lags = lags, \n",
    "            nodes = model_specification,\n",
    "            hidden_dim = 10,\n",
    "            n_layers = 1,\n",
    "            output_size= 1)\n",
    "        model.fit(trainloader, lr = .1, epochs = 4)\n",
    "        \n",
    "        # perform out of sample\n",
    "        output = model(features_test_tensor)\n",
    "        \n",
    "        # plt.plot(output.detach().numpy(), label = \"pred\")\n",
    "        # plt.plot(targets_test_tensor.detach().numpy(), label = \"target\")\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        \n",
    "        loss = model.criterion(output, targets_test_tensor)\n",
    "        score_nn += [loss.item()]\n",
    "        #=========================================================================================\n",
    "        #=========================================================================================\n",
    "\n",
    "    avg_score_nn = np.average(score_nn)\n",
    "    avg_score_har = np.average(score_har)\n",
    "    print(f\"model: {model_specification}\\navg score: {avg_score_nn}\")\n",
    "    print(f\"model: {model_specification}\\navg score: {avg_score_har}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
